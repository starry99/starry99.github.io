I"<h3 id="1-sridhar-mahadevan의-invited-talk-at-standford-univ-요약-2017년-12월">#1 Sridhar Mahadevan의 invited talk at Standford Univ. 요약<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <br />(2017년 12월)</h3>

<p>오늘날의 머신러닝 연구는 대부분 이제 학계에서가 아니라 산업체<sup>industry</sup>에서 이루어집니다. 보다 기초적인 이론을 자율주행 자동차와 같은 난제<sup>challenging problems</sup>에 적용시키는 것으로 바뀌었죠.</p>

<p>빌 게이츠는 뉴욕 타임즈와의 인터뷰에서 “기계가 스스로 학습할 수 있도록하는 획기적인 변혁<sup>breakthrough</sup>을 만들어낸다면, 그 가치는 마이크로소프트의 10배일 것이다”라고 말했습니다. 그의 말이 맞다면 머신러닝의 잠재적 시장가치는 약 5조 달러 정도 되겠지요.</p>

<p>이 경우, 학계에 있던 머신러닝 인재들이 산업계로 넘어간 사실이 놀랍지 않습니다. 훨씬 더 많은 데이터와 흥미로운 난제들이 가득하기까지 하니까요. 따라서 학계’만’의 머신러닝은 점차 줄고 있으며, 그 추세는 바뀌지 않을 것으로 보입니다.</p>

<p>어떠한 분야에서 연구<sup>research</sup>의 영향력은 <dfn info="투입량 대비 생산(결과)의 증가량이 줄어드는 현상">수확체감의 법칙</dfn><sup>diminishing returns</sup>을 따릅니다. 무슨 말인지 예를 들면, Havard의 유명한 정치학자 Gary King은 문서를 체계적으로 군집화<sup>clustering</sup>하는 방법에 대해 조사를 한 적이 있습니다. 그의 노예인 박사과정 학생은 모든 논문과 문헌을 뒤져서 총 250개의 알고리즘을 찾아냈습니다. 자 여기서, 누군가 251번째의 새로운 알고리즘을 발명하는게 얼마나 가치가 있을까요? 머신러닝에도 똑같은 이야기가 적용됩니다. GAN이든 강화학습이든 각 분야에서 수백개가 넘는 새로운 ‘방법’들이 논문화되었죠. 그중 대부분은 맨 처음의 원본 논문 이상으로 깊게 논의되지 않습니다. 그럼에도 새로운 방법을 이용한 새로운 논문들은 지금 이 순간에도 계속 나오고 있습니다</p>

<p>궁극적으로, 연구의 영향력이란 어떠한 새로운 분야에서 ‘선도자’가 될 때 최대가 됩니다. 그 분야에서 가장 처음으로 영향력 있는 논문을 쓴 사람은 연구적 명성의 대부분을 얻게 됩니다. 1984년 Leslie Valiant는 PAC Learning이란 분야를 개척한 “A Theory of the Learnable”라는 논문을 썼습니다. 현재 Google Scholar 인용 수는 6천개가 넘고, 수천개의 논문이 이 모델을 이용해 쓰여졌습니다. 하지만 CS분야 최고 영예의 상인 Turing Award는 분야를 개척한 공로로 인해 Leslie Valiant에게 돌아갔죠. 즉, 누군가의 모델을 응용한 n번째 저자가 되는게 아니라 새로운 분야를 개척하는 것이 이상적입니다.</p>

<p>요즘 머신러닝 학회에는 6천명이 넘는 사람들이 참석합니다. 남들이 안하는 거 하는 50여명이 참석했던 1985년의 학회 때와는 크게 달라졌죠. 이러한 분야에서 응용분야가 아니라 새로운 기초를 제시하는 것<sup>make a basic contribution</sup>은 매우 어렵습니다. 불가능하진 않지만 매우 어렵습니다. 도전해볼만 할 가치가 있는지 결정하는 것은 여러분의 몫입니다.니다.</p>

<hr />

<h3 id="2-mit-technology-review-2019년-1월">#2 MIT Technology Review<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> (2019년 1월)</h3>

<p>오늘날 사람들이 들어봤을 AI인공지능분야의 성과는 대부분이 딥러닝 덕분이다. 딥러닝은 통계학을 이용해 데이터의 패턴을 찾아서, 거의 인간 만큼이나 잘 ‘보고’ ‘듣게’ 만든다. 심지어 좁은 분야이지만 인간처럼 논리적인 근거에 따라 판단도 할 수 있다. 현재 구글 검색, 페이스북의 피드, 넷플릭스의 추천엔진 등에 사용되며, 헬스케어와 교육과 같은 분야도 큰 변화를 목전에 두고 있다.</p>

<p>비록 딥러닝이 대중에겐 AI의 중심으로 보일지라도, 사실 오랜 인공지능 연구의 역사에선 하나의 작은 변화일 뿐이다. 딥러닝이 해당 분야의 선두가 된 것은 아직 10년도 되지 않았다. 역사가 주는 교훈으로 판단한다면, 곧 딥러닝 또한 다른 무언가에게 선두를 내줄 가능성이 높다.</p>

<p>오랫동안 AI 분야에선 다양한 신기술이 등장했다가 지는 것을 반복해왔다. 우리는 arXiv의 ‘artificial intelligence’ 섹션에서 2018년 11월 18일 전까지의 16,625개 논문의 초록을 다운받은 후, 사용되는 단어에 대한 분석을 수행하였다. 아래 그래프는 arXiv에서 연도별로 다운받은 논문의 수이다.</p>

<p>존재하지 않는 이미지입니다.</p>

<p>사진 삭제
사진 설명을 입력하세요.</p>

<p>분석 결과 크게 3가지 트렌드를 알아냈다. 우선 90년대 말과 2000대 초반에 ‘machine learning’으로의 큰 변화가 있었으며, 2010년대 초반에는 ‘neural network’이란 단어가 급증했다. 그리고 최근 몇년간은 ‘reinforcement learning’이란 단어가 크게 성장하였다.</p>

<p>존재하지 않는 이미지입니다.</p>

<p>사진 삭제
사진 설명을 입력하세요.</p>

<p>존재하지 않는 이미지입니다.</p>

<p>사진 삭제
사진 설명을 입력하세요.</p>

<p>사실 몇가지 통계상 오류가 있다. ‘artificial intelligence’라는 단어는 50년대부터 등장했지만 arXiv의 AI 섹션은 1993년에 생겼다. 또한 모든 논문에 arXiv에 등재된 것도 아니다. 하지만 최근의 트렌드를 확인하는 데에는 충분한 데이터라고 본다.</p>

<p>최근 25년간 사용된 대부분의 기술들은 거의 비슷한 시기인 1950년대에 등장했다. 그후 성장과 추락을 반복해왔다. 예를 들어 neural network는 60년대에 피크를 쳤고 80년대에도 짧게 반짝 했다가 거의 사장되었지만, 최근 deep learning 때문에 엄청난 인기를 얻었다.</p>

<p>즉 매 10년마다 뭔가 다른 기술이 대세를 차지한다. 50년대 후반과 60년대는 neural network, 70년대는 various symbolic approach, 80년대는 knowledge-based system, 90년대는 Bayesian network, 2000년대는 support vector machine, 그리고 2010년대엔 다시 neural network이다.</p>

<p>2020년대에는 어떨까? 크게 다르지 않을 것으로 예상한다. 그렇다면 딥러닝의 시대는 거의 저물고 있다는 뜻이다. 수많은 이들이 다음 대세를 위해 아이디어를 연구하고 있다. 오래된 기술들이 다시 대세가 될 수도 있고, 아예 새로운 패러다임이 등장할 수 도 있다.</p>

<p>역자 주: AI의 한 분야인 딥러닝만 공부하는 것이 아니라 AI 자체를 공부하는 것이 필요하다.</p>

<p><br /><br /><br /></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://qr.ae/TWIb2C">https://qr.ae/TWIb2C</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://www.technologyreview.com/s/612768/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/">https://www.technologyreview.com/s/612768/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
:ET